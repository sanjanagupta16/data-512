### A2 Bias in Data

#### Purpose

The purpose is to identify potential sources of bias in a corpus of human-annotated data, and describe some implications of those biases. The analysis is performed the using the Jupyter notebook and all data, documentation, code and outputs are published in this GitHub repository for reference.


#### Data

Source data for Aggression and Toxicity in Wikipedia Talk project can be found on [Figshare](https://figshare.com/projects/Wikipedia_Talk/16731) and the schema can be found [here](https://meta.wikimedia.org/wiki/Research:Detox/Data_Release).
For an overview of the project, please refer the [Conversation AI](https://conversationai.github.io/) website.

For the purpose of this explatory analysis, the datasets used are:

- **Toxicity** - 160k labeled comments from English Wikipedia by approximately 10 annotators via Crowdflower on a spectrum of how toxic the comment is (perceived as likely to make people want to leave the discussion) to how healthy to conversation the contribution is.
- **Aggression** - 100k labeled comments from English Wikipedia by approximately 10 annotators via Crowdflower on how aggressive the comment was perceived to be along with some demographic data for each crowd-worker.


#### Output

To answer the research questions, exploratory analysis was performed. Each of these visualizations can be found in the output folder.


#### Packages

The following packages are used:
1. [numpy](https://numpy.org/)
2. [pandas](https://pandas.pydata.org/)
3. [matplotlib](https://matplotlib.org/)


#### Licenses

[MIT License](https://opensource.org/licenses/MIT) was used for this project.